# DLA-AI Experiment Results

This document summarizes the results of running the full set of simulated experiments for the Dynamic Layer-Adaptive AI (DLA-AI) framework. Each experiment uses a different configuration from the `configs/` directory. The metrics below are derived from the per-round history generated by `run_sim.py`.

## Summary Statistics

| Scenario | Total Rounds | Final Avg Param | Mean |Δ| | Std Param |
|---|---|---|---|---|
| config | 10 | -0.016198 | 0.008781 | 0.005678 |
| partition_equal | 20 | 0.011584 | 0.010959 | 0.012619 |
| partition_3_2 | 20 | -0.002768 | 0.004507 | 0.007081 |
| devices_5 | 20 | 0.003641 | 0.003788 | 0.004835 |
| devices_10 | 20 | 0.003480 | 0.000878 | 0.001106 |
| threshold_01 | 20 | 0.009857 | 0.010128 | 0.007458 |
| threshold_05 | 20 | 0.007703 | 0.008160 | 0.005083 |

* **Final Avg Param** – final global parameter mean at the end of all rounds.
* **Mean |Δ|** – average absolute deviation of the round-wise parameter mean from the final value.
* **Std Param** – standard deviation of the round-wise parameter mean.

## Observations

- Increasing the number of devices from 5 to 10 lowered the variability of the global parameter (`Std Param` dropped from 0.004835 to 0.001106) and slightly improved stability.
- Fine-grained partitioning (`partition_equal`) produced the highest variability, indicating that excessive partition granularity can inject noise into the training process.
- Lowering the idle threshold (`threshold_01`) yielded smoother convergence than the more restrictive `threshold_05` configuration, as more devices participated in each round.

## MNIST Real-Data Baseline

To demonstrate that the framework can train on real data, we executed an end-to-end experiment on the MNIST dataset. A simple
FedAvg baseline and a partitioned DLA-AI variant ran for two rounds over three devices (one local epoch per round).

| Method | Accuracy Round 1 | Accuracy Round 2 |
|---|---|---|
| FedAvg | 0.8758 | 0.9357 |
| DLA-AI | 0.2982 | 0.7778 |

## Non-viable Experiments

Due to time and dataset size constraints, extended evaluations on FEMNIST, CIFAR-10, UA-DETRAC, and industrial sensor datasets
remain out of scope. The results above therefore cover only the synthetic simulations and the MNIST demonstration.

